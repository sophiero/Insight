{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and shaping data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../../data/processed'\n",
    "\n",
    "def load_data(year, img_h=1400, img_w=1400):\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    data_dir = os.path.join(DATA_PATH, str(year))\n",
    "    frames_dir = os.path.join(data_dir, 'frames')\n",
    "    masks_dir = os.path.join(data_dir, 'masks')\n",
    "\n",
    "    for file in sorted(os.listdir(frames_dir)):\n",
    "        if file.startswith('R'):\n",
    "            filename = file.split('.')[0]\n",
    "\n",
    "            frame = np.load(os.path.join(frames_dir, filename + '.npy'))\n",
    "            mask = np.load(os.path.join(masks_dir, filename + '_labels.npy'))\n",
    "            X.append(frame[:img_h, :img_w, :])\n",
    "            y.append(mask[:img_h, :img_w])\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data so that columns are spectral bands and rows are pixels\n",
    "\n",
    "def reshape_data(X, y):\n",
    "    X_reshaped = X.reshape(-1, X.shape[-1])\n",
    "    y_reshaped = y.reshape(-1)\n",
    "\n",
    "    return X_reshaped, y_reshaped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression pipeline for pixel-based classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardizer(X):\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled\n",
    "\n",
    "def build_pipeline():  \n",
    "    pipeline = Pipeline([\n",
    "        ('standarize', FunctionTransformer(standardizer, validate=False)),\n",
    "        ('log_reg', LogisticRegression(solver='lbfgs', max_iter=300))])\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data(2017)\n",
    "X, y = reshape_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('standarize',\n",
       "                 FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
       "                                     func=<function standardizer at 0x122770f28>,\n",
       "                                     inv_kw_args=None, inverse_func=None,\n",
       "                                     kw_args=None, pass_y='deprecated',\n",
       "                                     validate=False)),\n",
       "                ('log_reg',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=300,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_pipeline = build_pipeline()\n",
    "log_reg_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance based on model coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  9,  7,  3,  4,  0, 11, 12,  1,  2,  8,  6,  5]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.abs(log_reg_pipeline['log_reg'].coef_)\n",
    "sorted_index = np.argsort(features)\n",
    "sorted_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating model on 2017 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_reg_pipeline.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intersection-over-union metric for image segmentation\n",
    "def iou(confusion_matrix):\n",
    "    tn, fp, fn, tp = confusion_matrix.ravel()\n",
    "    iou = tp / (tp + fn + fp)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92\n",
      "Intersection-over-Union: 0.77\n",
      "Confusion Matrix: \n",
      " [[7798564  322616]\n",
      " [ 580054 3058766]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95   8121180\n",
      "           1       0.90      0.84      0.87   3638820\n",
      "\n",
      "    accuracy                           0.92  11760000\n",
      "   macro avg       0.92      0.90      0.91  11760000\n",
      "weighted avg       0.92      0.92      0.92  11760000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_confusion_matrix = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "print('Accuracy: %.2f' % accuracy_score(y_val, y_pred))\n",
    "print('Intersection-over-Union: %.2f' % iou(val_confusion_matrix))\n",
    "print('Confusion Matrix: \\n', val_confusion_matrix)\n",
    "print('Classification report:\\n', classification_report(y_val, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
